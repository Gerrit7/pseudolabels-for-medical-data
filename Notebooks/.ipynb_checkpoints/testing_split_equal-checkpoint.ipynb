{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for testing split equal function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3417a6f1f430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mINFO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPathMNIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChestMNIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDermaMNIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOCTMNIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPneumoniaMNIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRetinaMNIST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mBreastMNIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrganMNISTAxial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrganMNISTCoronal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrganMNISTSagittal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from ..medmnist.info import INFO\n",
    "from ..medmnist.dataset import PathMNIST, ChestMNIST, DermaMNIST, OCTMNIST, PneumoniaMNIST, RetinaMNIST, \\\n",
    "    BreastMNIST, OrganMNISTAxial, OrganMNISTCoronal, OrganMNISTSagittal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareMedMNIST:\n",
    "    def __init__(self, input_args, dataset_info):\n",
    "\n",
    "        '''\n",
    "        input args\n",
    "            \"data_name\"         --> name of dataset                                                                                     --> string\n",
    "            \"data_root\"         --> folder of medmnist data                                                                             --> string\n",
    "            \"output_root\"       --> folder for saving results                                                                           --> string\n",
    "            \"n_epochs\"          --> n of epochs in training                                                                             --> int\n",
    "            \"batch_size\"        --> batch size                                                                                          --> int\n",
    "            \"learning_rate\"     --> learning rate of the optimizer                                                                      --> float\n",
    "            \"momentum\"          --> momentum of optimizer                                                                               --> float\n",
    "            \"train_size\"        --> percentage of data for training                                                                     --> int\n",
    "            \"weight_decay\"      --> weight decay                                                                                        --> float\n",
    "            \"model\"             --> used model architecture                                                                             --> string\n",
    "            \"n_studentnets\"     --> n of studentnet iterations in pseudolabeling                                                        --> int\n",
    "            \"operation\"         --> train a model (False) or make predictions (True)                                                    --> boolean\n",
    "            \"task\"              --> task: \"Pseudolabel\", \"MTSS\", \"NoisyStudent\", \"Baseline\"                                             --> string\n",
    "            \"optimizer\"         --> optimizer                                                                                           --> string\n",
    "            \"LR_decay\"          --> decay of learning rate: default 0                                                                   --> float\n",
    "            \"LR_milestones\"     --> milestones for lr decay                                                                             --> int\n",
    "            \"Loss_function\"     --> loss function                                                                                       --> string\n",
    "            \"augmentations\"     --> list of augmenations                                                                                --> list\n",
    "            \"download\"          --> download the data                                                                                   --> boolean\n",
    "        \n",
    "        dataset_info\n",
    "            \"description\"       --> Description of dataset\n",
    "            \"url\"               --> download url\n",
    "            \"MD5\"               -->\n",
    "            \"task\"              --> dataset task: \"multi-class\", \"binary-class\", \"ordinal regression\", \"multi-label, binary-class\"\n",
    "            \"label\":            --> labels dictionary with class number and description\n",
    "            \"n_channels\"        --> binary image (1), rgb image (3)\n",
    "            \"n_samples\":        --> number of dataset splits: \"train\": XX, \"val\": XX, \"test\": XX\n",
    "            \"license\":          --> licence for usage\n",
    "        '''\n",
    "        self.input_args = input_args\n",
    "        self.dataset_info = dataset_info\n",
    "\n",
    "        # create transformations of dataset \n",
    "        transform = self.createTransform(augmentations=self.input_args[\"augmentations\"])\n",
    "\n",
    "        # define dataset for training/ validation/ testing\n",
    "        self.dataset_train   = self.prepareDataSet('train', transform)\n",
    "        self.dataset_val     = self.prepareDataSet('train', transform)\n",
    "        self.dataset_test     = self.prepareDataSet('train', transform)\n",
    "\n",
    "        # create dataloader for training/ validation/ testing\n",
    "        self.dataloader_train = self.createDataLoader(self.dataset_train)\n",
    "        self.dataloader_val = self.createDataLoader(self.dataset_val)\n",
    "        self.dataloader_test = self.createDataLoader(self.dataset_test)\n",
    "\n",
    "        # split dataset if needed for training/ validation/ testing\n",
    "        self.train_dataset_labeled, self.train_subset_labeled, self.train_dataset_unlabeled, self.train_subset_unlabeled = self.splitDataset(self.dataset_train, self.dataloader_train)\n",
    "        #self.val_dataset_labeled, self.val_subset_labeled, self.val_dataset_unlabeled, self.val_subset_unlabeled = self.splitDataset(self.dataset_val, self.dataloader_val, 'val')\n",
    "        #self.train_dataset_labeled, self.train_subset_labeled, self.train_dataset_unlabeled, self.train_subset_unlabeled = self.splitDataset(self.dataset_test, self.dataloader_test, 'train')\n",
    "\n",
    "\n",
    "\n",
    "    def createTransform(self, image_size=32, augmentations=[]):\n",
    "        aug_values = {\n",
    "            \"CenterCrop\"   : {\"size\": 10},\n",
    "            \"ColorJitter\"  : {\"brightness\": 0, \"contrast\": 0, \"saturation\": 0, \"hue\": 0},\n",
    "            \"GaussianBlur\" : {\"kernel\": [3,3], \"sigma\" : 0.1},\n",
    "            \"Normalize\"    : {\"mean\": [0.5], \"std\": [0.5]},\n",
    "            \"RandomHorizontalFlip\" : {\"probability\": 0.5},\n",
    "            \"RandomVerticalFlip\" : {\"probability\": 0.5},\n",
    "            \"RandomRotation\" : {\"degrees\": [-20, 20]}\t\n",
    "        }\n",
    "\n",
    "        tranform_compose_list = [transforms.ToTensor()]\n",
    "        if self.input_args[\"model\"] == \"EfficientNet-b0\" or self.input_args[\"model\"] == \"EfficientNet-b1\" or self.input_args[\"model\"] == \"EfficientNet-b7\":\n",
    "            tranform_compose_list.append(transforms.Resize(256))\n",
    "        \n",
    "        for aug in self.input_args[\"augmentations\"]:\n",
    "            if aug == \"centerCrop\":\n",
    "                tranform_compose_list.append(transforms.CenterCrop(\n",
    "                            aug_values[\"CenterCrop\"][\"size\"]))\n",
    "            elif aug == \"colorJitter\":\n",
    "                tranform_compose_list.append(transforms.ColorJitter(\n",
    "                            brightness=aug_values[\"ColorJitter\"][\"brightness\"], \n",
    "                            contrast=aug_values[\"ColorJitter\"][\"contrast\"],\n",
    "                            saturation=aug_values[\"ColorJitter\"][\"saturation\"], \n",
    "                            hue=aug_values[\"ColorJitter\"][\"hue\"]))\n",
    "            elif aug == \"gaussianBlur\":\n",
    "                tranform_compose_list.append(transforms.GaussianBlur(\n",
    "                            kernel_size=aug_values[\"GaussianBlur\"][\"kernel\"], \n",
    "                            sigma=aug_values[\"GaussianBlur\"][\"sigma\"]))\n",
    "            elif aug ==\"normalize\":\n",
    "                tranform_compose_list.append(transforms.Normalize(\n",
    "                            mean=aug_values[\"Normalize\"][\"mean\"], \n",
    "                            std=aug_values[\"Normalize\"][\"std\"]))\n",
    "            elif aug ==\"randomHorizontalFlip\":\n",
    "                tranform_compose_list.append(transforms.RandomHorizontalFlip(\n",
    "                            p=aug_values[\"RandomHorizontalFlip\"][\"probability\"]))\n",
    "            elif aug ==\"randomVerticalFlip\":\n",
    "                tranform_compose_list.append(transforms.RandomVerticalFlip(\n",
    "                            p=aug_values[\"RandomVerticalFlip\"][\"probability\"]))\n",
    "            elif aug ==\"randomRotation\":\n",
    "                tranform_compose_list.append(transforms.RandomRotation(\n",
    "                            degrees=aug_values[\"RandomRotation\"][\"degrees\"]))\n",
    "            #else:\n",
    "                #print(\"augmentation not found!\")\n",
    "        \n",
    "        transform = transforms.Compose(tranform_compose_list)\n",
    "        return transform\n",
    "\n",
    "    def prepareDataSet(self, split, transform):\n",
    "\n",
    "        flag_to_class = {\n",
    "            \"pathmnist\": PathMNIST,\n",
    "            \"chestmnist\": ChestMNIST,\n",
    "            \"dermamnist\": DermaMNIST,\n",
    "            \"octmnist\": OCTMNIST,\n",
    "            \"pneumoniamnist\": PneumoniaMNIST,\n",
    "            \"retinamnist\": RetinaMNIST,\n",
    "            \"breastmnist\": BreastMNIST,\n",
    "            \"organmnist_axial\": OrganMNISTAxial,\n",
    "            \"organmnist_coronal\": OrganMNISTCoronal,\n",
    "            \"organmnist_sagittal\": OrganMNISTSagittal,\n",
    "        }\n",
    "        DataClass = flag_to_class[self.input_args[\"data_name\"]]\n",
    "\n",
    "        dataset = DataClass(root=self.input_args[\"data_root\"],\n",
    "                            split=split,\n",
    "                            transform=transform,\n",
    "                            download=self.input_args[\"download\"])\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def createDataLoader(self, dataset):\n",
    "        data_loader = data.DataLoader(dataset=dataset,\n",
    "                                    batch_size=self.input_args[\"batch_size\"],\n",
    "                                    shuffle=True)\n",
    "        \n",
    "        return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepareData = PrepareMedMNIST()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
